{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egSN8Y2x_SPm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "\n",
        "# Define the dimensions of the license plate image\n",
        "plate_width = 200\n",
        "plate_height = 100\n",
        "\n",
        "# Define the font and font size for the character labels\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "font_size = 4\n",
        "font_thickness = 6\n",
        "\n",
        "# Define the number of images to create\n",
        "num_images = 1000\n",
        "\n",
        "# Create the images and labels\n",
        "images = []\n",
        "labels = []\n",
        "for i in range(100):\n",
        "    # Create a blank white image\n",
        "    image = np.ones((plate_height, plate_width, 3), dtype=np.uint8) * 255\n",
        "\n",
        "    # Choose a random character for each of the 7 spots on the license plate\n",
        "    label = ''\n",
        "    for j in range(7):\n",
        "        character = characters[np.random.randint(len(characters))]\n",
        "        label += character\n",
        "\n",
        "        # Draw the character on the image\n",
        "        text_size, _ = cv2.getTextSize(character, font, font_size, font_thickness)\n",
        "        x = int((plate_width / 7) * (j + 0.5) - text_size[0] / 2)\n",
        "        y = int(plate_height / 2 + text_size[1] / 2)\n",
        "        cv2.putText(image, character, (x, y), font, font_size, (0, 0, 0), font_thickness)\n",
        "\n",
        "    # Add some random noise to the image\n",
        "    noise = np.random.normal(loc=0, scale=20, size=(plate_height, plate_width, 3)).astype(np.int32)\n",
        "    image = np.clip(image.astype(np.int32) + noise, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Add the image and label to the dataset\n",
        "    images.append(image)\n",
        "    labels.append(label)\n"
      ],
      "metadata": {
        "id": "0MjCZuuI_kIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_plate_graph(image):\n",
        "    # Convert the image to grayscale\n",
        "    print(image)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create a graph\n",
        "    graph = nx.Graph()\n",
        "\n",
        "    # Add nodes to the graph for each character in the license plate\n",
        "    for i, contour in enumerate(contours):\n",
        "        x,y,w,h = cv2.boundingRect(contour)\n",
        "        graph.add_node(i, pos=(x,y))\n",
        "\n",
        "    # Add edges to the graph for characters that are close together\n",
        "    for i in range(len(contours)):\n",
        "        for j in range(i+1, len(contours)):\n",
        "            if np.linalg.norm(np.array(graph.nodes[i]['pos']) - np.array(graph.nodes[j]['pos'])) < 50:\n",
        "                graph.add_edge(i, j)\n",
        "\n",
        "    return graph\n"
      ],
      "metadata": {
        "id": "00Mad1Hb_0eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a GNN model\n",
        "class PlateGNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(PlateGNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_dim, hidden_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, output_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(output_dim, output_dim)\n",
        "        self.fc2 = nn.Linear(output_dim, output_dim)\n",
        "        self.fc3 = nn.Linear(output_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.matmul(adj, x)\n",
        "        return x\n",
        "\n",
        "# Define the loss function\n",
        "def loss_fn(output, labels):\n",
        "    loss = F.cross_entropy(output, labels)\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "# Create the GNN model\n",
        "model = PlateGNN(input_dim=1, hidden_dim=16, output_dim=10)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i in range(len(images)):\n",
        "        # Create a graph representation of the license plate image\n",
        "        graph = create_plate_graph(images[i])\n",
        "\n",
        "        # Create an adjacency matrix from the graph\n",
        "        adj = nx.adjacency_matrix(graph)\n",
        "        print(adj)\n",
        "        adj = torch.FloatTensor(adj.toarray())\n",
        "\n",
        "        # Create a tensor of node features (all 0s)\n",
        "        node_features = torch.zeros(adj.shape[0], 1)\n",
        "\n",
        "        # Feed the graph and node features into the model to predict character labels\n",
        "        output = model(node_features, adj)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_fn(output, torch.LongTensor([labels[i]]))\n",
        "\n",
        "        # Zero the gradients, backward propagate, and update the model parameters\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the running loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print the epoch number and running loss\n",
        "    print('Epoch [%d], loss: %.4f' % (epoch+1, running_loss / len(images)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TEOP72_6_TOW",
        "outputId": "bcce4abb-ea6d-4951-9007-a1d82fa437e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[255 255 255]\n",
            "  [237 255 254]\n",
            "  [249 255 252]\n",
            "  ...\n",
            "  [255 255 255]\n",
            "  [255 255 247]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[242 255 255]\n",
            "  [213 238 238]\n",
            "  [245 240 246]\n",
            "  ...\n",
            "  [211 255 229]\n",
            "  [255 255 255]\n",
            "  [251 240 255]]\n",
            "\n",
            " [[255 255 255]\n",
            "  [254 255 255]\n",
            "  [255 228 255]\n",
            "  ...\n",
            "  [253 229 255]\n",
            "  [255 255 255]\n",
            "  [235 219 255]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[239 255 255]\n",
            "  [252 239 239]\n",
            "  [227 254 255]\n",
            "  ...\n",
            "  [226 245 255]\n",
            "  [255 255 255]\n",
            "  [255 255 241]]\n",
            "\n",
            " [[223 255 252]\n",
            "  [243 238 255]\n",
            "  [255 250 244]\n",
            "  ...\n",
            "  [243 218 252]\n",
            "  [255 255 255]\n",
            "  [254 226 234]]\n",
            "\n",
            " [[255 239 255]\n",
            "  [255 235 254]\n",
            "  [248 252 248]\n",
            "  ...\n",
            "  [221 243 235]\n",
            "  [246 255 255]\n",
            "  [230 255 245]]]\n",
            "  (0, 2)\t1\n",
            "  (0, 3)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 4)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 5)\t1\n",
            "  (3, 0)\t1\n",
            "  (3, 1)\t1\n",
            "  (3, 8)\t1\n",
            "  (4, 1)\t1\n",
            "  (4, 6)\t1\n",
            "  (4, 9)\t1\n",
            "  (4, 10)\t1\n",
            "  (5, 2)\t1\n",
            "  (5, 13)\t1\n",
            "  (6, 4)\t1\n",
            "  (6, 7)\t1\n",
            "  (6, 9)\t1\n",
            "  (6, 10)\t1\n",
            "  (7, 6)\t1\n",
            "  (7, 9)\t1\n",
            "  (7, 10)\t1\n",
            "  (8, 3)\t1\n",
            "  (8, 10)\t1\n",
            "  (8, 11)\t1\n",
            "  (8, 12)\t1\n",
            "  (9, 4)\t1\n",
            "  (9, 6)\t1\n",
            "  (9, 7)\t1\n",
            "  (9, 10)\t1\n",
            "  (10, 4)\t1\n",
            "  (10, 6)\t1\n",
            "  (10, 7)\t1\n",
            "  (10, 8)\t1\n",
            "  (10, 9)\t1\n",
            "  (11, 8)\t1\n",
            "  (11, 12)\t1\n",
            "  (12, 8)\t1\n",
            "  (12, 11)\t1\n",
            "  (13, 5)\t1\n",
            "  (13, 14)\t1\n",
            "  (14, 13)\t1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2b489ebbdde7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Feed the graph and node features into the model to predict character labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-2b489ebbdde7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 3, 3], expected input[1, 200, 100, 1] to have 1 channels, but got 200 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kSeOAyF1_2EL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}